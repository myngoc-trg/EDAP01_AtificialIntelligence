{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python based viewer tool for \"Probabilistic Reasoning over time\", EDAP01 Artificial Intelligence\n",
    "This notebook, in particular the Dashboard / visualisation, has been originally provided by Alexander DÃ¼rr, teaching assistant on the course, spring term 2021. It is based on the ideas and structure of the original Java skeleton for this assignment, provided by Elin A. Topp. Contact me (elin_a.topp at cs.lth.se) in case you need help with the visualisation stuff, it might require some fiddling with Python, Jupyter notebooks, widgets and other thingees!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Installing and activating widgets for Jupyter Notebook\n",
    "To be able to display the visualization (dashboard,animations,etc.) you have to initially install the package  if you don't have it yet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: You might also need this for the widgets to work in a notebook (not in Jupyter Lab)\n",
    "This command enables the widget extension for jupyter notebook \n",
    "\n",
    "Menu bar > Help > Launch Classic Notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of the underlying models \n",
    "### (and example code for visualisation of your own solution)\n",
    "\n",
    "In _models_, all the actually interesting stuff is located, and in _Filters_ you later write your own core code for filtering / smoothing. Right now, it is only a dummy implementation that returns what is fed into it.\n",
    "\n",
    "Note that the simulation / visualization (second code cell, \"inspecting the models, option 2\") assumes to have access to an object of type _Localizer_ which in turn expects the filtering / smoothing to happen in respective methods in _Filters.FilterSmoother_. This also measn, that you can use the visualisation to inspect your tracking / smoothing approach **without changing anything in _Localizer.py_ or _Dashboard.py_**. You can of course use the implementation of the control code for step wise filtering / smoothing in _Localizer.initialise()_ and _Localizer.update()_ as an inspiration for your own implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your tasks 1) and 2)\n",
    "\n",
    "Inspect the **sensor models** given in _models_ with the help of the two ways to visualise them suggested below (or add other visualisations). Prepare yourself to answer the support questions given in the instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation as heatmap or simple print-outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from view_control.Localizer import Localizer\n",
    "import numpy as np\n",
    "\n",
    "# Testing the models, e.g., for a 4x4 grid\n",
    "\n",
    "states = StateModel( 4, 4)\n",
    "loc = Localizer( states, 0, 0) # initialising with sensor model \"NUF\" (0) and filtering only (windowLength = 0)\n",
    "tMat = loc.get_transition_model()\n",
    "sVecs = loc.get_observation_model()\n",
    "tMat.plot_T() # plotting the T-matrix as heatmap\n",
    "sVecs.plot_o_diags() # plotting the sensor model as heatmap\n",
    "\n",
    "print(sVecs.get_o_reading(0)) # print the diagonal matrix for sensor reading \"0\", i.e. position <0, 0> in the grid\n",
    "print(sVecs.get_o_reading(None)) # print the diagonal matrix for \"no sensor reading\"\n",
    "\n",
    "print(loc.update())\n",
    "\n",
    "np.set_printoptions(threshold = np.inf)\n",
    "print(sVecs.sum_diags()) # checking that all probabilities for the sensor readings sum up to 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation in the grid-world\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In view_control.Dashboard, there is simply the handling of all the thread based visualisation provided, \n",
    "# no changes needed, but feel free...\n",
    "\n",
    "# The dashboard creates a state model of the dimensions given by ROWS and COLS, and sets up the respective \n",
    "# Transition and Observation models, as well as an instance of class Localizer. The Localizer calls at the \n",
    "# moment stubb methods in Filters.FilterSmoother, which just send back the original \n",
    "# probability distribution - no filtering / smoothing is actually done. It is your task to implement something \n",
    "# useful there in the next step.\n",
    "\n",
    "from view_control import *\n",
    "\n",
    "# Default (minimum) size of the grid. Max for visualisation is set to 10, beyond that things get messy\n",
    "ROWS = 4\n",
    "COLS = 4\n",
    "\n",
    "# Non-uniform failure is the default sensor, sensor 0. \n",
    "# Default for filtering or smoothing is filtering only (t_minus_k = 0)\n",
    "sensorType = 0 # NUF-sensor\n",
    "t_minus_k = 0 # filtering only\n",
    "\n",
    "dash = Dashboard(ROWS, COLS, sensorType, t_minus_k)\n",
    "display(dash.db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
